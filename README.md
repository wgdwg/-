# -机器学习之回归模型-一元线性回归理论与最小二乘法实现

线性回归是一种线性模型，它假设输入变量x与单个输出变量y之间存在线性关系。

具体的说，就是利用线性回归模型，从一组输入变量的线性组合中，计算出输出变量y。

正常两个点确定一条直线，但是实际情况往往是海量数据，而不是2组数据，即大量的点，而不是两个点，我们要的是一条尽量可能拟合这些点分布状态的一条直线，即所有点到直线的距离之和最小，即损失函数最小。

正常情况下，输入属性是有多个，在线性回归中，最小二乘法就是找到一条直线，使得样本到所有直线得欧氏距离最小。我们最后求得得是函数取得最小值时候的参数。

我们的函数是一个二次的函数，图像为抛物线，开口向上，二元函数，直接分别对参数w和b求偏导，并令导数等于0，导数为0的点就是函数的最小值点，也就是误差最小时候，此时的参数w，b就是我们要求的。

采用数据集data.csv，画出散点图，带入公式做出线性回归拟合直线，求出参数值w,b,并求出此时的最小损失函数，即误差最小，使得线性回归直线尽可能覆盖所有散点。


